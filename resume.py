resume = """
# 张长龙个人简历
**电话**：13824794702  
**邮箱**：louisgagaheehee@gmail.com  
**现居城市**：深圳市  
**微信**：13824794702  
**年龄**：27岁  
**当前状态**：在职  
**求职意向**：后端开发

## 专业技能
1. 掌握Java基础知识，涵盖集合、反射、多线程、线程池、锁以及基本数据结构。熟悉JVM内存模型、内存管理、ZGC、三色标记法等回收算法，以及G1、CMS等常见垃圾收集器，了解JVM调优，有解决对象提前晋升调优经验。
2. 熟悉SpringBoot、SpringMVC、Mybatis等开源框架，了解SpringCloud Alibaba微服务组件，熟悉服务治理、熔断降级、负载均衡相关知识。
3. 掌握Golang基础知识，拥有基于Go语言开发分布式系统的经验，深入理解Go的并发模型（goroutines和channels），并能有效设计高并发、高性能的分布式服务。
4. 掌握Python编程，具有AIGC领域的应用开发经验，掌握提示工程及多模态输入处理。具备AI工作流设计及Agent开发能力，拥有构建会话式RAG服务的实战经验。
5. 熟悉MySQL、PostgreSQL，熟悉B+树索引特点、事务以及常见优化手段，了解MVCC多版本并发控制原理、三大日志及其作用，有过冷热分离、数据迁移、大数据量处理、慢SQL优化、索引优化等实操经验。
6. 熟悉MongoDB，掌握其应用场景，基于MongoDB Atlas实现文档向量化存储，了解慢查询优化基本手段以及主从、集群等高可用方案。
7. 熟练掌握Redis数据结构、应用场景、持久化与过期及内存淘汰策略。熟悉多路复用、Cluster模式与扩缩容，能处理缓存一致性、热/大key问题。了解Raft、Gossip及一致性哈希，熟悉分布式锁，研读过Redisson相关源码。
8. 掌握Kubernetes基本应用场景以及底层原理，如基本组件、网络通信模型、数据卷挂载机制，了解其服务发现、负载均衡、服务保活、容器资源调度等机制，熟悉常用的Kubectl客户端命令。
9. 掌握Docker容器化开发，独立编写多阶段Dockerfile构建应用镜像，通过本地容器部署调试后端服务，运用Docker Compose编排开发环境组件，集成CI实现自动化构建，具备容器网络配置实践经验。
10. 了解ElasticSearch分布式搜索引擎，了解倒排索引、分词器以及滚动查询，熟悉其基本使用场景。
11. 熟悉Google Pub/Sub、Kafka消息中间件基本设计思想以及应用场景。熟悉消息积压、防重、防丢、削峰填谷等常规解决方案。熟悉消息的可靠投递、顺序消费。了解顺序写入、零拷贝等性能优化场景。

## 教育经历
**广东海洋大学** - 计算机科学与技术 本科 数学与计算机学院 2017年09月 - 2021年06月
证书：CET - 4

## 工作经历
1. **深圳市逻辑控股科技有限公司** - 后端开发工程师 2022年12月 - 至今
    - 从0到1负责Nova App的后端系统设计、开发、部署、上线。参与社交、Mining等核心功能的开发。参与对系统进行优化降本、代码逻辑重构、文档输出等工作。
    - 从0到1负责RAG AI对话服务的后端系统设计，开发。
2. **深圳市云歌人工智能技术有限公司** - 服务端开发工程师 产品研发部 2022年07月 - 2022年11月
    - 负责灵鸽APP投递服务以及消息中心服务的开发、日常迭代，功能模块的重构以及日常维护，主导消息中心服务的设计与开发，与PC/移动客户端的联调与对接。
3. **萨摩耶数字科技有限公司** - 数据科学工程师(Java) 数据业务部 2021年06月 - 2022年07月
    - 负责天心系统、渠道管理系统、以及Canal中间件的日常开发与维护，需求评审与Code Review，以及对生产问题的排查与解决。
4. **深圳市TCL新技术有限公司** - 后端开发实习生 云平台 鸿鹄实验室 2020年11月 - 2021年03月
    - 了解企业开发流程，参与基本的表设计与功能模块开发。

## 项目经验
### ChatBooster - 后端开发工程师 2024年07月 - 至今
#### 项目描述
ChatBooster是一款企业赋能平台，整合WhatsApp、Facebook、Instagram等多渠道资源，为企业构建一站式解决方案，助力业绩提升。平台借助RAG AI技术，提升客户支持效率，运用自动化对话式AI增强客户互动体验。同时，基于Pixel精准追踪广告投放关键事件，深度解析转化率数据，为优化广告投放策略提供数据支撑，实现广告效果最大化与精细化管理。
#### 工作职责
1. 从0到1负责调研Langchain、Huggingface等相关技术栈，设计并搭建RAG应用程序。
2. 搭建短链系统，基于埋点和用户画像反哺营销策略和广告投放方案。
#### 项目架构
基于Golang+Kratos构建核心服务，数据层采用Gorm/MySQL+Redis缓存，Protocol定义通信协议。集成GCP Pub/Sub异步消息队列与Cloud Storage对象存储，DevOps链涵盖GCP代码托管、CI/CD流水线、K8s编排及监控告警模块，保障高可用与弹性扩展。
#### 技术要点以及成果
1. 人力成本缩减15%，人工接管率稳定<15%，释放40%客服人力转向高价值业务。
2. 通过AI Agent实现语义分析及意图识别，预设多场景回复策略，AI自主判断用户意图并匹配回复方案，以预设话术及人工服务兜底，覆盖68%的常见场景，显著降低人工服务压力。
3. 集成Gemini多模态AI引擎，实现Text+Audio+Image To Text统一解析，支持多语言识别（含小语种/方言，准确率>90%）及情绪分析，图片识别准确率>90%，扩展复杂业务场景处理能力，通过多模态语义理解提升意图识别准确率，结合上下文对话管理优化交互体验。
4. 集成DeepSeek深度思考模型，针对中文语境优化语义理解与意图识别，提升中文对话交互精准度，结合上下文理解与多轮对话管理，显著增强复杂中文场景处理能力，中文意图识别准确率高达90%以上。
5. 设计并实现多平台大语言模型的Prompt工程化，设计基于角色预设与知识约束的动态Prompt模板，构建支持图文跨模态的动态模板，基于RAGAs等工具构建自动化评估框架，结合人工标注，量化问答相关性（92%）与准确性（85%），迭代优化幻觉率20%降至9%。
6. 集成DuckDuckGoSearch API实现联网检索，通过LLM动态调用搜索引擎获取最新资讯，结合语义分析与数据摘要生成时效性回答，支持科技、金融等多领域实时查询。
7. 依托MongoDB构建1536维向量库，采用BM25+余弦相似度混合检索（权重比6:4），文档召回率达90%以上。
8. 设计租户隔离方案，并实现基于特定知识库范围的精准AI问答功能，保障多客户环境下的数据隐私与应用灵活性。
9. 实现短链功能，基于埋点统计UV/PV及渠道来源以及收集用户画像，反哺广告投放策略以及驱动营销策略优化，识别高转化渠道提升ROI，获客成本降低25%。

### Nova App - 后端开发工程师 2022年12月 - 2024年06月
#### 项目描述
一款基于社交+Mining的面向海外用户产品。用户可在App上发表动态获得Nova Token，并每日进行一次Mining操作，24小时后结算Nova Token。项目上线后在两周内注册用户达到25万人，业务增长迅速，平均日活超过20w以上。
#### 项目架构
以Java+Spring为核心，采用Spring Boot基本框架。并基于Google Cloud Platform及Kubernetes进行部署与运维，借助Mysql+MongoDB作持久层存储中间件、ES为搜索引擎、Redis为应用缓存。通过Cloud Flare实现限流、安防及网关层缓存与流量网关，Feign作RPC框架，消息中间件选Google Pub/Sub，引入Firebase实现用户系统等。
#### 工作职责
对Nova后端账户模块、社交模块、Mining模块进行包括但不限于业务逻辑重构和优化、功能开发与迭代、服务性能优化、数据库性能优化。保证数据在长链路流转的过程中的可靠性和一致性。
#### 技术要点以及成果
1. 参与实现feed流，对用户following data功能基于redis的zset重构，对following data提前聚合，相关接口响应时间提高300%，避免了数据读扩散现象。
2. 在业务快速增长阶段对数据库的索引、慢SQL、以及引入cloudflare缓存+限流进行优化，系统性能整体提升30%以上。
3. 设计并实现贴文敏感词过滤以及敏感视频检测，检测成功率达99%。
4. 参与Mining功能的重构和优化，以延时任务+消息队列的形式替换定时任务方案，将集中的数据库压力分散，提高数据库可用性，数据实时性提高50%。
5. 设计并实现基于区域推荐的机制，以排行榜的形式实时更新区域热贴排行榜。
6. 基于消息队列异步解耦，缓解用户关注、取关、点赞等社交行为带来的写扩散问题，服务吞吐量提升。
7. 基于Firebase快速设计并实现通知推送服务、以及账户登录注册、第三方社交账号绑定。
8. 从0到1负责app对应后台管理系统的实现，包括但不限于用户数据统计、贴文管理、评论管理等等。

### 灵鸽App 2022年07月 - 2022年11月
#### 项目描述
灵鸽主要服务于猎头与用户，业务范围定位在高端人才招聘，通过猎头找用户、猎头邀请用户的模式为企业去寻找合适的候选人。
#### 项目架构
以SpringBoot为基本框架，使用MySql、ES作为持久层数据库，以Redis作为缓存层，采用Kubernates+容器化进行部署并配合Nacos作为注册中心，以Ingress-Naginx作为流量网关，以Dubbo作为RPC框架，配置中心采用Apoll，消息中间件采用RocketMQ。
#### 工作职责
1. 对投递服务历史项目进行迁移逻辑重构、性能优化，对需求进行分析以及方案设计。
2. 主导消息中心服务的功能模块设计、数据存储设计以及性能优化与迭代。
3. 业务问题的排查、定位与解决。
#### 技术要点以及成果
1. 对猎头推荐信息查询接口进行优化以及重构，接口RT优化300%。
2. 设计消息已读未读存储方案，减少80%消息状态数据存储量。
3. 基于Redis有序集合缓存热点消息如系统消息，基于哈希结构缓存消息已读未读状态，提高高频接口查询响应速度。
4. 基于时间范围进行限制，优化全量已读消息的场景，避免慢查询发生。
5. 优化红点未读消息统计逻辑，基于MQ由全量统计变增量统计，优化接口RT，并以调度任务进行数据一致性兜底。
6. 对慢SQL进行索引优化，使得查询效率提高60%。
7. 基于openCV实现自动化测试解决方案（基于图像识别的验证码处理模块），成功率达95%以上。

### 天心系统 2021年06月 - 2022年07月
#### 项目描述
将贷后业务、风控、管理、运营集为一体的科技产品，其模块有智能分案、催收作业主流程、用户排班、渠道管理、工单模块、风险指标监控、外包模块、内部论坛、内部聊天。负责公司的风险指标监控，如入催率、逾期率、逾期金额、坏账风险、回收率等，同时对逾期用户进行智能化催收，系统主要面向内部催收人员以及业务人员使用。每年可为公司催回数亿借贷款，一定程度保障公司的现金流。
#### 系统架构
以SSM为基本框架，主要使用Mysql、Redis、ES作为数据库选型，消息中间件使用Kafka进行消息通信，同时使用Sentinel保证整体高可用。
#### 工作职责
1. 参与需求设计评审、代码评审以及与业务方进行需求讨论以及调整。
2. 对于功能模块的设计、以及重构已有的系统模块，如聊天模块、论坛模块等。
3. 对系统生产问题的排查、定位以及提供解决方案，如解决自动语音外呼异常、数据跑批异常等。
4. 系统性能方面优化，如慢SQL优化等，使得系统可用时间达99%以上。
#### 技术要点以及成果
1. 优化亿级数据处理手段，利用索引解决深度分页的问题，并且将处理时间由20h优化至3h。
2. 优化语音外呼任务，实现系统外呼渠道切换自动化并实现加权随机轮询算法，提高容错性以及伸缩性。
3. 优化用户操作日志的存储以及查询速度，并根据规则统计用户的闲置时间。
4. 利用Canal+MQ对客户还款金额的更新延迟由20分钟优化至准实时1 - 5秒。
5. 通过策略模式以与工厂模式及反射实现风控策略的懒加载，提升项目启动速度，并使代码更优雅。
6. 通过定时任务以及拦截器日志埋点，解决用户session无法过期导致长时间占用连接的问题。
7. 基于ES进行数据冷热分离，优化业务查询场景性能，使热数据查询速度提高80%，冷数据查询提高30%。
8. 通过对JVM调参，解决系统因对象提前晋升至老年代导致频繁Full GC而内存溢出的问题。
9. 根据业务场景参与优化慢SQL、数据表优化，系统整体查询性能提升20%。
10. 对群聊模块进行重构，实现修改用户信息后自动退出、进入对应的群，省去维护群聊的人力时间。

### 渠道管理系统 2021年06月 - 2022年07月
#### 项目描述
天心系统的前置系统，从核心系统拉取数据并预处理。负责天心系统几十万入催客户的处理，包括前置数据整理、前置系统跑批、转发客户实时还款信息。迭代与维护跑批预处理逻辑、账户核心系统客户数据等。
#### 技术要点
1. 负责项目的日常迭代与维护。
2. 对接渠道进行客户账款消息上送至其他系统。
3. 通过SQL拆分以及优化慢SQL，对数据跑批时间进行优化，使得跑批时间减少30%。
4. 生产问题的排查与提供解决方案。

### Canal中间件 2021年06月 - 2022年07月
#### 项目描述
阿里巴巴旗下开源中间件，主要用途是基于MySQL数据库增量日志解析，提供增量数据订阅和消费，通过公司研发的中间层dcs，将同步数据分发至各个从库。
#### 工作职责
负责系统日常业务工作、问题处理，协调各个开发部门的数据同步工作。
#### 技术要点
1. 参与了公司Canal分布式部署的高可用方案的设计，并与运维集成至公司发布平台。
2. 公司Canal中间件的日常维护以及实例配置更新。
3. 参与解决数据同步丢失等生产问题的排查与解决。
4. 参与公司数据库迁移后的数据同步、数据恢复工作，保证了数据的0丢失。
""" 